#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Nov 14 10:35:29 2017

@author: paszczak
"""
import json
import unicodedata
import re
import itertools



directory= "data/"


def SimplifyAuthorsInGoogleScholar (nameList):
    #Google scholar format: BM Paszcza; Scopus format: Paszcza B.; MA format: mess - bartosz paszcza, paszcza bartosz, b m paszcza
    newList = []
    
    for name in nameList:
        name = name.replace(".", "")
        name = name.split(None, 1)
        try:
            name = name[1]
            name = re.sub('[^a-zA-Z0-9\n\.]', ' ', name)
            name = unicodedata.normalize('NFKD', name).encode('ASCII', 'ignore')
            
        except IndexError:
            name = ""  # no surname
        #name = name.split(None, 1)[1]
        name = name.lower()
        name = str(name)
        newList.append(name)
        
    return newList

def SimplifyAuthorsInScopus (nameList):
    #Google scholar format: BM Paszcza; Scopus format: Paszcza B.; MA format: mess - bartosz paszcza, paszcza bartosz, b m paszcza
    newList = []
    for name in nameList:
        name = name.replace(".", "")
        name = name.replace("-","")
        name = name.rsplit(None, 1)[0]
        name = name.lower()
        
        name = unicodedata.normalize('NFKD', name).encode('ASCII', 'ignore')
        name = str(name)
        
        newList.append(name)
    return newList
    
def SimplifyAuthorsInMA (nameList):
    newList = []
    for name in nameList:
        name = name.lower()
        name = name.replace(".", "")
        names = name.split()
        for element in names:
            element = re.sub('[^a-zA-Z0-9\n\.]', ' ', element)
            element = unicodedata.normalize('NFKD', element).encode('ASCII', 'ignore')
            element = str(element)
            newList.append(element)
    
    return newList
    #Google scholar format: BM Paszcza; Scopus format: Paszcza B.; MA format: mess - bartosz paszcza, paszcza bartosz, b m paszcza
    #remove initials: start from beggining, if single letter followed by space (on place 0) -> remove those two signs, repeat
    

#Ti -> simplified Titles, removing spaces, repeated letters, vowels
def simplifyTitle (text):
    """function normalisng text to lowercase letters, removing all non-alphanumeric signs, then removing all spaces, repeated (double) letters, and vowels from string"""
    text = text.lower()
    text = re.sub('[^a-zA-Z0-9\n\.]', ' ', text)
    text = text.replace(".", "")
    text = text.replace(" ", "")
    text = " ".join(text.split())
    
    text = ''.join(ch for ch, _ in itertools.groupby(text)) #remove all repeated letters, illiterate -> iliterate
    
    vowels = ('a', 'e', 'i', 'o', 'u')
    text = ''.join([l for l in text if l not in vowels]) #remove all vowels
    
    text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore')
    
    text = str(text).encode('utf-8')
    return (str(text))

def unifySchema(doc):
    if "_ - S - _ - U" in doc:
        doc["_ - SU"] = str(doc["_ - S - _ - U"]).split(", ")
        doc.pop("_ - S - _ - U", None)
    elif "_ - SU" in doc:
        doc["_ - SU"] = str(doc["_ - SU"]).split(", ")
    elif "_ - S" in doc:
        doc["_ - SU"] = str(doc["_ - S"])
    
    if "_ - AA - _ - AuN" in doc:
        doc["_ - AA"] = str(doc["_ - AA - _ - AuN"]).split(", ")
        doc.pop("_ - AA - _ - AuN", None)
    elif "_ - AA" in doc:
        doc["_ - AA"] = str(doc["_ - AA"]).split(", ")
    elif "_ - AA - _ - name" in doc:
        doc["_ - AA"] = str(doc["_ - AA - _ - name"]).split(", ")
        doc.pop("_ - AA - _ - name", None)
        
    doc["simplifiedTi"] = simplifyTitle(doc["_ - Ti"])
    
    return doc

####################################
    




def findUnmatched (dbJson, idString, matches):
    unmatchedElements = []
    
    for element in dbJson:
        flag = 0
        for match in matches:
            if idString in match:
                if element["_ - Id"] == match[idString]:
                    flag = 1
        
        if flag == 0:
            unmatchedElements.append(dict(element))
    
    return unmatchedElements
                  

####################  

#read in matches, read in conflicts
with open(str(directory+"overlap_400_matches.json")) as data_file:    
    matchesJson = json.load(data_file)
    
limit = 400
filename = "_keyword_1_natural_sciences.json"
directory= "data/filteredJSONs/"

with open(str(directory+"MA"+filename)) as data_file:    
    maJson = json.load(data_file)
    maJson400 = []
    x = 0
    for doc in maJson:
        doc = unifySchema(doc)
        doc["_ - AA"] = SimplifyAuthorsInMA(doc["_ - AA"])
        doc["_ - Venue - FullName"] = str(doc["_ - Venue - FullName"] or "")
        doc["_ - Venue - Issue"] = str(doc["_ - Venue - Issue"] or "")
        doc["_ - Venue - Volume"] = str(doc["_ - Venue - Volume"] or "")
        
        if x < limit:
            maJson400.append(doc)
            x = x+1
        
        #with open(str(directory+"MA_sample"+filename), 'w') as fp:
        #    json.dump(maJson400, fp)
        
with open(str(directory+"scopus"+filename)) as data_file:    
    scopusJson = json.load(data_file)
    scopusJson400 = []
    x = 0
    
    for doc in scopusJson:
        doc = unifySchema(doc)
        doc["_ - AA"] = SimplifyAuthorsInScopus(doc["_ - AA"])
        doc["_ - Venue - Issue"] = str(doc["_ - Venue - Issue"] or "")
        doc["_ - Venue - Volume"] = str(doc["_ - Venue - Volume"] or "")
        doc["_ - Y"] = int(doc["_ - Y"][:4])
        doc["_ - CC"] = int(doc["_ - CC"])
        
        if x < limit:
            scopusJson400.append(doc)
            x = x+1
        
        #with open(str(directory+"scopus_sample"+filename), 'w') as fp:
        #    json.dump(scopusJson400, fp)

with open(str(directory+"google_scholar"+filename)) as data_file:    
    gsJson = json.load(data_file)
    gsJson400 = []
    x = 0
    for doc in gsJson:
        doc = unifySchema(doc)
        doc["_ - Id"] = x
        doc["_ - AA"] = SimplifyAuthorsInGoogleScholar(doc["_ - AA"])
        doc["_ - Y"] = int(doc["_ - Y"] or "0") 
        doc["_ - CC"] = int(doc["_ - CC"] or "0")
        doc["_ - gsType"] = str(doc["_ - gsType"] or "none")
        
        if x < limit:
            gsJson400.append(doc)
        x = x+1


########################################
        
unmatchedMA = findUnmatched(maJson400, "maID", matchesJson)
unmatchedScopus = findUnmatched(scopusJson400, "scopusID", matchesJson)
unmatchedGS = findUnmatched(gsJson400, "gsID", matchesJson)


with open(str(directory+"ma_sample400_unmatched"+filename), 'w+') as fp:
            json.dump(unmatchedMA, fp)
with open(str(directory+"scopus_sample400_unmatched"+filename), 'w+') as fp:
            json.dump(unmatchedScopus, fp)
with open(str(directory+"gs_sample400_unmatched"+filename), 'w+') as fp:
            json.dump(unmatchedGS, fp)